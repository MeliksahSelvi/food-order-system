server:
  port: 8181

logging:
  level:
    com.food.order.system: DEBUG



order-service:
  payment-request-topic-name: payment-request
  payment-response-topic-name: payment-response
  restaurant-approval-request-topic-name: restaurant-approval-request
  restaurant-approval-response-topic-name: restaurant-approval-response
  outbox-scheduler-fixed-rate: 10000
  outbox-scheduler-initial-delay: 10000

spring:
  jpa:
    #open-in-view false vererek; spring defaultunda persistence context'i açık bırakmaya zorlayan ayarı disable ettik
    # yani view layer proxy initialization ile başlayabilecek. Eğer proxy ile başlamazsa DB connect uzun süre açık kalacak
    #ve bu durumda db performanceyi olumsuz etkileyecek.
    open-in-view: false
    show-sql: true
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
  datasource:
    #binaryTransfer=true ile veriler binary şekilde aktarılacak yani verileri dönüştürmeye çalışmayacak
    #reWriteBatchedInserts ile toplu kayıt işlemlerini daha hızlı yapabileceğiz.
    #Toplu kayıtlarda birden çok ekleme yerine birden çok değere sahip tek bir ekleme ifadesi çalışacak.
    #UUID kullanıyoruz ve postgre'de UUID türünü kontrol eden özellikleri devre dışı bırakmak için string ifadeleri type olmadan DB'ye gönderecek
    url: jdbc:postgresql://localhost:5432/postgres?currentSchema=order&binaryTransfer=true&reWriteBatchedInserts=true&stringtype=unspecified
    #todo username password encrypt edilebilir.
    username: postgres
    password: 1234
    driver-class-name: org.postgresql.Driver
  sql:
    init:
      mode: always
      schema-locations: classpath:init-schema.sql
      platform: postgres


kafka-config:
  bootstrap-servers: localhost:19092, localhost:29092, localhost:39092
  schema-registry-url-key: schema.registry.url
  schema-registry-url: http://localhost:8081
  #3 partitions' ile bir topic üzerinde 3 consumer çolıştırabiliriz.
  num-of-partitions: 3
  replication-factor: 3

kafka-producer-config:
  key-serializer-class: org.apache.kafka.common.serialization.StringSerializer
  value-serializer-class: io.confluent.kafka.serializers.KafkaAvroSerializer
  #kafka'nın desteklediği sıkıştırma türleri arasında snappy CPU kullanımı,sıkıştırma,hız,ağ arasında iyi bir denge sağlar.
  compression-type: snappy
  #acks all -> kafka producer gönderdiği mesajı onaylamadan önce broker'dan onay bekleyeceği anlamına gelir.
  acks: all
  batch-size: 16384
  batch-size-boost-factor: 100
  #linger-ms -> producer verileri datayı göndermeden ünce delay ekler. producer üzerinde az yük olduğu zaman her seferinde
  #az veri göndermek yerine toplu gönderim yapılarak verilerin gönderilmesi sağlanması için işe yarar.
  linger-ms: 5
  #broker'dan producer'a bu süre boyunca yanıt gelmezse timeout error verir.
  request-timeout-ms: 60000
  #producer'da hata olursa tekrar denenme sayısı
  retry-count: 5

kafka-consumer-config:
  key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
  value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
  #consumer-group-id özelliği ile bir consumer'ın bir ürünü consume ederken her seferinde baştan başlamamasını sağlar.
  #her bir consumer'ın sahip olduğu offset değeri consumer group ile eşleştirilir.
  payment-consumer-group-id: payment-topic-consumer
  restaurant-approval-consumer-group-id: restaurant-approval-topic-consumer
#  customer-group-id: customer-topic-consumer
  #auto-offset-reset ile kafka serverinde offset kalmamışsa baştan okumaya başlar.yani bir kafka topic ilk defa okunduğunda baştan başlar.
  #mesela latest yaparsak offset sondan başlar. bu da serverimiz sadece ayağa kalktıktan sonra gelen verileri okuyabilir demektir.
  auto-offset-reset: earliest
  specific-avro-reader-key: specific.avro.reader
  specific-avro-reader: true
  #batch-listener -> verileri tek tek consume yerine toplu consume etmeyi sağlar.
  batch-listener: true
  # auto-startup true verince kafka consumer hemen consume işlemine başlar.
  auto-startup: true
  #concurrency- level 1'den büyük yapılırsa o kadar thread oluşturur.
  concurrency-level: 3
  # broker 10 saniyede bir consumer'dan yaşıyor belirtisi alması gerekir.bu süre dolunce signal yoksa consumer group'tan o consumer'ı çıkarır.
  session-timeout-ms: 10000
  # broker'ın consumer'a signal gönderme sıklığı
  heartbeat-interval-ms: 3000
  #user threads içindir.messaging processing logic çok ağırsa bu zamandan fazla sürebilir.Bu durumda coordinator consumer'ı ölü işaretler
  #ve coordinator diğer consumer'lara partition'lar atamak için yeni bir dengeleme turu tetikleyecektir.
  max-poll-interval-ms: 300000
  #consumer bir seferde 500 veri getirebilir.
  max-poll-records: 500
  #consumer her bir fetch işleminde en fazla bu kadar byte'a sahip veri alabilir.
  max-partition-fetch-bytes-default: 1048576
  max-partition-fetch-bytes-boost-factor: 1
  #topic üzerinde veri yoksa, consumer'ın150 ms boyunca veri varmı diye check etmesini engeller.
  poll-timeout-ms: 150


